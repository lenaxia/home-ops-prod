apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: &appname localai
  namespace: home
spec:
  interval: 20m
  chart:
    spec:
      chart: app-template
      version: 1.5.0
      interval: 5m
      sourceRef:
        kind: HelmRepository
        name: bjw-s-charts
        namespace: flux-system
  # See https://github.com/bjw-s/helm-charts/blob/main/charts/library/common/values.yaml
  values:

    image: 
      repository: quay.io/go-skynet/local-ai
      tag: master

    env:
    - name: THREADS
      value: 8 
    - name: CONTEXT_SIZE
      value: 1024
    - name: MODELS_PATH
      value: "/models"
    - name: IMAGE_PATH
      value: /tmp
    - name: BUILD_TYPE
      value: openblas
    - name: GO_TAGS
      value: stablediffusion
    - name: DEBUG
      value: "true"
        #
        #    lifecycle:
        #      postStart:
        #        exec:
        #          command:
        #            - /bin/bash
        #            - -c
        #            - /postStart.sh

    initContainers:
      download-model:
        image: busybox@sha256:b5d6fe0712636ceb7430189de28819e195e8966372edfc2d9409d79402a0dc16
        command: ["/bin/sh", "-c"]
        args:
          - |
            wget "https://s3.${SECRET_DEV_DOMAIN}/public/stablediffusion.tar" -P /tmp
            tar -xzvf /tmp/stablediffusion.tar -C $MODELS_PATH
            rm -rf /tmp/stablediffusion.tar

        env:
          - name: URL
            value: "https://gpt4all.io/models/ggml-gpt4all-j.bin"
          - name: MODELS_PATH
            value: "/models"
        volumeMounts:
          - name: models 
            mountPath: /models
        securityContext:
          runAsUser: 0

    persistence:
      models:
        enabled: true
        storageClass: local-path
        size: 30Gi
        type: pvc
        accessMode: ReadWriteOnce
          #      poststart:
          #        enabled: true
          #        type: configMap
          #        name: poststart-sh
          #        subPath: postStart.sh
          #        mountPath: /postStart.sh
          #        defaultMode: 0777

    service:
      main:
        type: LoadBalancer
        ports:
          http:
            port: &port 8080

    ingress:
      main:
        enabled: true
        annotations:
          hajimari.io/enable: "true"
          hajimari.io/icon: game-icons:meal
          hajimari.io/info: Local AI
          hajimari.io/group: documents
          cert-manager.io/cluster-issuer: "letsencrypt-production"
          traefik.ingress.kubernetes.io/router.entrypoints: "websecure"
          traefik.ingress.kubernetes.io/router.middlewares: networking-chain-authelia@kubernetescrd
        hosts:
        - host: &uri ai.${SECRET_DEV_DOMAIN}
          paths:
          - path: /
            pathType: Prefix
        tls:
        - hosts:
            - *uri
          secretName: *uri
    
    nodeSelector:
      node-role.kubernetes.io/worker: "true"

    probes:
      liveness: &probes
        enabled: false
        custom: true
        spec:
          httpGet:
            path: /
            port: *port
          initialDelaySeconds: 0
          periodSeconds: 30 
          timeoutSeconds: 1
          failureThreshold: 3
      readiness: *probes
      startup:
        enabled: false
