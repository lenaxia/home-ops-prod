name: hermes2-pro
mmap: true
parameters:
  model: huggingface://NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF/Hermes-2-Pro-Llama-3-8B-Q8_0.gguf
template:
  chat_message: |
    <|im_start|>{{if eq .RoleName "assistant"}}assistant{{else if eq .RoleName "system"}}system{{else if eq .RoleName "tool"}}tool{{else if eq .RoleName "user"}}user{{end}}

    {{- if .FunctionCall}}
    Function call:
    {{- else if eq .RoleName "tool"}}
    Function response:
    {{- end}}
    {{- if .Content}}
    {{.Content}}
    {{- else if .FunctionCall}}
    {{toJson .FunctionCall}}
    {{- end}}
    <|im_end|>
  function: |
    <|im_start|>system

    You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:
    <tools>
    {{range .Functions}}
    {'type': 'function', 'function': {'name': '{{.Name}}', 'description': '{{.Description}}', 'parameters': {{toJson .Parameters}} }}
    {{end}}
    </tools>
    Use the following pydantic model json schema for each tool call you will make:
    {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}<|im_end|><|im_start|>assistant
    Function call:
  chat: |
    <|begin_of_text|><|im_start|>user
    {{.Input }} <|im_end|><|im_start|>assistant
  completion: |
    {{.Input}}
context_size: 8192
f16: true
gpu_layers: 33
stopwords:
- <|im_end|>
- <dummy32000>
- "<|im_end|>"
usage: |
      curl $LOCALAI/v1/chat/completions -H "Content-Type: application/json" -d '{
          "model": "llama3-8b-instruct",
          "messages": [{"role": "user", "content": "How are you doing?", "temperature": 0.1}]
      }'
