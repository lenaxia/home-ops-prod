name: llama3-8b-basic
mmap: true
parameters:
  #model: huggingface://second-state/Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf
  #model: huggingface://QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct.Q8_0.gguf
  model: 96519624f6fae501db4dbf45abe1c168

template:
  chat: |
    <|begin_of_text|><|start_header_id|>user<|end_header_id|>
    {{.Input }} <|eot_id|><|start_header_id|>assistant<|end_header_id|>
  completion: |
    {{.Input}}
context_size: 8192
f16: true
gpu_layers: 33
stopwords:
- <|im_end|>
- <dummy32000>
- "<|eot_id|>"
usage: |
      curl $LOCALAI/v1/chat/completions -H "Content-Type: application/json" -d '{
          "model": "llama3-8b-instruct",
          "messages": [{"role": "user", "content": "How are you doing?", "temperature": 0.1}]
      }'
