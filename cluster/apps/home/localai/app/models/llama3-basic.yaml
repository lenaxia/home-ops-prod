name: llama3-8b-basic
mmap: true
parameters:
  #model: huggingface://second-state/Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf
  model: huggingface://QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct.Q8_0.gguf

template:
  chat: |
    <|begin_of_text|>{{.Input }} <|start_header_id|>assistant<|end_header_id|>
  completion: |
    {{.Input}}
context_size: 8192
f16: true
gpu_layers: 33
stopwords:
- <|im_end|>
- <dummy32000>
- "<|eot_id|>"
usage: |
      curl http://localhost:8080/v1/chat/completions -H "Content-Type: application/json" -d '{
          "model": "llama3-8b-instruct",
          "messages": [{"role": "user", "content": "How are you doing?", "temperature": 0.1}]
      }'
