name: neuralhermes-2.5-7b
mmap: true
parameters:
  model: huggingface://TheBloke/NeuralHermes-2.5-Mistral-7B-GGUF/neuralhermes-2.5-mistral-7b.Q8_0.gguf
function:
  # disable injecting the "answer" tool
  #disable_no_action: true
  ## This allows the grammar to also return messages
  #grammar_message: true
  ## Suffix to add to the grammar
  #grammar_prefix: '<tool_call>\n'
  #return_name_in_function_response: true
  ## Without grammar uncomment the lines below
  ## Warning: this is relying only on the capability of the
  ## LLM model to generate the correct function call.
  no_grammar: true
  ##json_regex_match: "(?s)<tool_call>(.*?)</tool_call>?"
  #replace_results:
  #  - key: "^(\\w+)\\s*:"
  #    value: "\"$1\""
  #  - key: "<tool_call>"
  #    value: ""
  #  - key: "Processing user message."
  #    value: ""
  #  - key: "Continuing conversation."
  #    value: ""
  #  - key: "&quot;"
  #    value: "\""
  #  - key: "(?s)^[^{\\[]*"
  #    value: ""
  #  - key: "(?s)[^}\\]]*$"
  #    value: ""
  #  - key: "'([^']*?)'"
  #    value: "_DQUOTE_${1}_DQUOTE_"
  #  - key: "\\\""
  #    value: "__TEMP_QUOTE__"
  #  - key: "\""
  #    value: "\\\""
  #  - key: "\\'"
  #    value: "'"
  #  - key: "_DQUOTE_"
  #    value: "\""
  #  - key: "__TEMP_QUOTE__"
  #    value: "\""

template:
  chat_message: |
    <|im_start|>{{if eq .RoleName "assistant"}}assistant{{else if eq .RoleName "system"}}system{{else if eq .RoleName "tool"}}tool{{else if eq .RoleName "user"}}user{{end}}
    {{- if .FunctionCall }}
    <tool_call>
    {{- else if eq .RoleName "tool" }}
    <tool_response>
    {{- end }}
    {{- if .Content}}
    {{.Content }}
    {{- end }}
    {{- if .FunctionCall}}
    {{toJson .FunctionCall}}
    {{- end }}
    {{- if .FunctionCall }}
    </tool_call>
    {{- else if eq .RoleName "tool" }}
    </tool_response>
    {{- end }}<|im_end|>
  # https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B-GGUF#prompt-format-for-function-calling
  function: |
    <|im_start|>system
    You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:
    <tools>
    {{range .Functions}}
    {'type': 'function', 'function': {'name': '{{.Name}}', 'description': '{{.Description}}', 'parameters': {{toJson .Parameters}} }}
    {{end}}
    </tools>
    Use the following pydantic model json schema for each tool call you will make:
    {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}
    For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:
    <tool_call>
    {'arguments': <args-dict>, 'name': <function-name>}
    </tool_call><|im_end|>
    {{.Input -}}
    <|im_start|>assistant
    <tool_call>
  chat: |
    {{.Input}}
    <|im_start|>assistant
  completion: |
    {{.Input}}
context_size: 8192
f16: true
gpu_layers: 33
stopwords:
- <|im_end|>
- <dummy32000>
- "\n</tool_call>"
- "\n\n\n"
usage: |
      curl $LOCALAI/v1/chat/completions -H "Content-Type: application/json" -d '{
          "model": "neuralhermes-2.5-7b",
          "messages": [{"role": "user", "content": "How are you doing?", "temperature": 0.1}]
      }'
